{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9f785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os # accessing directory structure\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea5a872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horses\\testfile.csv\n",
      "['horses\\\\horses_1990.csv', 'horses\\\\horses_1991.csv', 'horses\\\\horses_1992.csv', 'horses\\\\horses_1993.csv', 'horses\\\\horses_1994.csv', 'horses\\\\horses_1995.csv', 'horses\\\\horses_1996.csv', 'horses\\\\horses_1997.csv', 'horses\\\\horses_1998.csv', 'horses\\\\horses_1999.csv', 'horses\\\\horses_2000.csv', 'horses\\\\horses_2001.csv', 'horses\\\\horses_2002.csv', 'horses\\\\horses_2003.csv', 'horses\\\\horses_2004.csv', 'horses\\\\horses_2005.csv', 'horses\\\\horses_2006.csv', 'horses\\\\horses_2007.csv', 'horses\\\\horses_2008.csv', 'horses\\\\horses_2009.csv', 'horses\\\\horses_2010.csv', 'horses\\\\horses_2011.csv', 'horses\\\\horses_2012.csv', 'horses\\\\horses_2013.csv', 'horses\\\\horses_2014.csv', 'horses\\\\horses_2015.csv', 'horses\\\\horses_2016.csv', 'horses\\\\horses_2017.csv', 'horses\\\\horses_2018.csv', 'horses\\\\horses_2019.csv', 'horses\\\\horses_2020.csv']\n",
      "['horses\\\\races_1990.csv', 'horses\\\\races_1991.csv', 'horses\\\\races_1992.csv', 'horses\\\\races_1993.csv', 'horses\\\\races_1994.csv', 'horses\\\\races_1995.csv', 'horses\\\\races_1996.csv', 'horses\\\\races_1997.csv', 'horses\\\\races_1998.csv', 'horses\\\\races_1999.csv', 'horses\\\\races_2000.csv', 'horses\\\\races_2001.csv', 'horses\\\\races_2002.csv', 'horses\\\\races_2003.csv', 'horses\\\\races_2004.csv', 'horses\\\\races_2005.csv', 'horses\\\\races_2006.csv', 'horses\\\\races_2007.csv', 'horses\\\\races_2008.csv', 'horses\\\\races_2009.csv', 'horses\\\\races_2010.csv', 'horses\\\\races_2011.csv', 'horses\\\\races_2012.csv', 'horses\\\\races_2013.csv', 'horses\\\\races_2014.csv', 'horses\\\\races_2015.csv', 'horses\\\\races_2016.csv', 'horses\\\\races_2017.csv', 'horses\\\\races_2018.csv', 'horses\\\\races_2019.csv', 'horses\\\\races_2020.csv']\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('horses'):\n",
    "    horse_files = []\n",
    "    race_files = []\n",
    "    for filename in filenames:\n",
    "        if \"horse\" in filename:\n",
    "            horse_files.append(os.path.join(dirname, filename))\n",
    "        elif \"race\" in filename:\n",
    "            race_files.append(os.path.join(dirname, filename))\n",
    "    print(os.path.join(dirname, filename))\n",
    "    print(horse_files)\n",
    "    print(race_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75dc685b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3266: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "d:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3266: DtypeWarning: Columns (27) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4107315 rows and 28 columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             rid         horseName  age  saddle  decimalPrice  isFav  \\\n",
       "0        271018        Combermere  6.0     0.0      0.222222      0   \n",
       "1        271018     Royal Battery  6.0     0.0      0.090909      0   \n",
       "2        271018           Just So  7.0     0.0      0.029412      0   \n",
       "3        271018  Mandraki Shuffle  8.0     0.0      0.090909      0   \n",
       "4        271018    Turnberry Dawn  8.0     0.0      0.047619      0   \n",
       "...         ...               ...  ...     ...           ...    ...   \n",
       "4107310  415090         Beefeater  8.0     6.0      0.030303      0   \n",
       "4107311  415090     Aimee's Jewel  4.0    11.0      0.153846      0   \n",
       "4107312  415090     Times Ticking  5.0     8.0      0.044053      0   \n",
       "4107313  415090      Shadows Cast  8.0     3.0      0.041152      0   \n",
       "4107314  415090        Awesome Al  7.0    12.0      0.016393      0   \n",
       "\n",
       "              trainerName        jockeyName  position positionL  ...  OR  \\\n",
       "0               R G Frost           J Frost         1       NaN  ... NaN   \n",
       "1              D H Barons           S Earle         2        10  ... NaN   \n",
       "2             J D Roberts        S Burrough         3        15  ... NaN   \n",
       "3         Oliver Sherwood        M Richards         4        20  ... NaN   \n",
       "4             T B Hallett        P Richards         5      dist  ... NaN   \n",
       "...                   ...               ...       ...       ...  ...  ..   \n",
       "4107310  Roydon Bergerson     Hazel Schofer         7       shd  ... NaN   \n",
       "4107311      Trudy Keegan     Lisa Allpress         8        .5  ... NaN   \n",
       "4107312    Alby Macgregor  Jonathan Riddell         9        hd  ... NaN   \n",
       "4107313     Mark Oulaghan  Johnathan Parkes        10         1  ... NaN   \n",
       "4107314      Buddy Lammas       Ryan Bishop        11      2.75  ... NaN   \n",
       "\n",
       "              father          mother          gfather  runners    margin  \\\n",
       "0            Absalom  Queen's Parade   Sovereign Path       14  1.521003   \n",
       "1        Norfolk Air      All At Sea     Man The Rail       14  1.521003   \n",
       "2              Sousa    Just Camilla      Ascertain I       14  1.521003   \n",
       "3           Mandalus      Indictment      Desert Call       14  1.521003   \n",
       "4          Fair Turn    Shuil Alainn         Levanter       14  1.521003   \n",
       "...              ...             ...              ...      ...       ...   \n",
       "4107310      Alamosa          Karaka  Kings Island II       11  1.191591   \n",
       "4107311      Proisir    Aimee's Idol         Colombia       11  1.191591   \n",
       "4107312    Tavistock       Laoghaire             Pins       11  1.191591   \n",
       "4107313  Per Incanto       Ages Past           Slavic       11  1.191591   \n",
       "4107314      Alamosa       Awesome I   High Chaparral       11  1.191591   \n",
       "\n",
       "         weight  res_win  res_place   price  \n",
       "0            69      1.0        1.0     NaN  \n",
       "1            69      0.0        1.0     NaN  \n",
       "2            66      0.0        1.0     NaN  \n",
       "3            69      0.0        0.0     NaN  \n",
       "4            69      0.0        0.0     NaN  \n",
       "...         ...      ...        ...     ...  \n",
       "4107310      58      0.0        0.0    32/1  \n",
       "4107311      57      0.0        0.0    11/2  \n",
       "4107312      58      0.0        0.0  217/10  \n",
       "4107313      58      0.0        0.0  233/10  \n",
       "4107314      57      0.0        0.0    60/1  \n",
       "\n",
       "[4107315 rows x 28 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nRowsRead = None # specify 'None' if want to read whole file\n",
    "df1 = pd.DataFrame()\n",
    "for file in horse_files:\n",
    "    csv_data = pd.read_csv(file, delimiter=',', nrows = nRowsRead)\n",
    "    df1 = df1.append(csv_data, ignore_index=True)\n",
    "df1.dataframeName = 'horses'\n",
    "nRow, nCol = df1.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')\n",
    "df1.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2698468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>horseName</th>\n",
       "      <th>age</th>\n",
       "      <th>saddle</th>\n",
       "      <th>decimalPrice</th>\n",
       "      <th>isFav</th>\n",
       "      <th>trainerName</th>\n",
       "      <th>jockeyName</th>\n",
       "      <th>position</th>\n",
       "      <th>RPR</th>\n",
       "      <th>TR</th>\n",
       "      <th>OR</th>\n",
       "      <th>weight</th>\n",
       "      <th>res_win</th>\n",
       "      <th>res_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271018</td>\n",
       "      <td>Combermere</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>R G Frost</td>\n",
       "      <td>J Frost</td>\n",
       "      <td>1</td>\n",
       "      <td>111.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271018</td>\n",
       "      <td>Royal Battery</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>D H Barons</td>\n",
       "      <td>S Earle</td>\n",
       "      <td>2</td>\n",
       "      <td>101.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>271018</td>\n",
       "      <td>Just So</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0</td>\n",
       "      <td>J D Roberts</td>\n",
       "      <td>S Burrough</td>\n",
       "      <td>3</td>\n",
       "      <td>86.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271018</td>\n",
       "      <td>Mandraki Shuffle</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>Oliver Sherwood</td>\n",
       "      <td>M Richards</td>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271018</td>\n",
       "      <td>Turnberry Dawn</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0</td>\n",
       "      <td>T B Hallett</td>\n",
       "      <td>P Richards</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rid         horseName  age  saddle  decimalPrice  isFav  \\\n",
       "0  271018        Combermere  6.0     0.0      0.222222      0   \n",
       "1  271018     Royal Battery  6.0     0.0      0.090909      0   \n",
       "2  271018           Just So  7.0     0.0      0.029412      0   \n",
       "3  271018  Mandraki Shuffle  8.0     0.0      0.090909      0   \n",
       "4  271018    Turnberry Dawn  8.0     0.0      0.047619      0   \n",
       "\n",
       "       trainerName  jockeyName  position    RPR    TR  OR  weight  res_win  \\\n",
       "0        R G Frost     J Frost         1  111.0  94.0 NaN      69      1.0   \n",
       "1       D H Barons     S Earle         2  101.0  88.0 NaN      69      0.0   \n",
       "2      J D Roberts  S Burrough         3   86.0  71.0 NaN      66      0.0   \n",
       "3  Oliver Sherwood  M Richards         4   66.0  65.0 NaN      69      0.0   \n",
       "4      T B Hallett  P Richards         5    NaN  45.0 NaN      69      0.0   \n",
       "\n",
       "   res_place  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        0.0  \n",
       "4        0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop some columns\n",
    "df1 = df1.drop(['positionL', 'dist', 'weightSt', 'weightLb', 'overWeight', 'outHandicap', 'headGear', 'father', \n",
    "         'mother', 'gfather', 'margin', 'runners', 'price'], axis=1)\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc74ea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 396572 rows and 19 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>course</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>rclass</th>\n",
       "      <th>band</th>\n",
       "      <th>ages</th>\n",
       "      <th>distance</th>\n",
       "      <th>condition</th>\n",
       "      <th>hurdles</th>\n",
       "      <th>prizes</th>\n",
       "      <th>winningTime</th>\n",
       "      <th>prize</th>\n",
       "      <th>metric</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>ncond</th>\n",
       "      <th>class</th>\n",
       "      <th>currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271018</td>\n",
       "      <td>Exeter</td>\n",
       "      <td>03:15</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>David Garrett Memorial Challenge Trophy Novice...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6-8yo</td>\n",
       "      <td>3m1f</td>\n",
       "      <td>Soft</td>\n",
       "      <td>19 fences</td>\n",
       "      <td>[2922.5, 875.0, 420.0, 192.5]</td>\n",
       "      <td>398.3</td>\n",
       "      <td>4409.0</td>\n",
       "      <td>5028.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275156</td>\n",
       "      <td>Tramore (IRE)</td>\n",
       "      <td>02:00</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>Tattersalls Mares E.B.F. Novice Chase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2m</td>\n",
       "      <td>Soft</td>\n",
       "      <td>12 fences</td>\n",
       "      <td>[]</td>\n",
       "      <td>267.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3218.0</td>\n",
       "      <td>IE</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282203</td>\n",
       "      <td>Catterick</td>\n",
       "      <td>02:45</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>Scotch Corner Handicap Chase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1m7½f</td>\n",
       "      <td>Good To Firm</td>\n",
       "      <td>12 fences</td>\n",
       "      <td>[2238.0, 618.0, 294.0]</td>\n",
       "      <td>238.0</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>3116.5</td>\n",
       "      <td>GB</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298761</td>\n",
       "      <td>Cheltenham</td>\n",
       "      <td>02:30</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>A. S. W. Handicap Hurdle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2m</td>\n",
       "      <td>Good To Firm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[5117.0, 1526.0, 728.0, 329.0]</td>\n",
       "      <td>243.8</td>\n",
       "      <td>7700.0</td>\n",
       "      <td>3218.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301118</td>\n",
       "      <td>Windsor</td>\n",
       "      <td>03:30</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>Touchen End Handicap Hurdle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2m6f</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2344.8, 652.8, 314.4]</td>\n",
       "      <td>330.7</td>\n",
       "      <td>3312.0</td>\n",
       "      <td>4424.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rid         course   time      date  \\\n",
       "0  271018         Exeter  03:15  90/01/01   \n",
       "1  275156  Tramore (IRE)  02:00  90/01/01   \n",
       "2  282203      Catterick  02:45  90/01/01   \n",
       "3  298761     Cheltenham  02:30  90/01/01   \n",
       "4  301118        Windsor  03:30  90/01/01   \n",
       "\n",
       "                                               title rclass   band   ages  \\\n",
       "0  David Garrett Memorial Challenge Trophy Novice...    NaN    NaN  6-8yo   \n",
       "1              Tattersalls Mares E.B.F. Novice Chase    NaN    NaN    NaN   \n",
       "2                       Scotch Corner Handicap Chase    NaN  0-125    NaN   \n",
       "3                           A. S. W. Handicap Hurdle    NaN    NaN    NaN   \n",
       "4                        Touchen End Handicap Hurdle    NaN  0-115    NaN   \n",
       "\n",
       "  distance     condition    hurdles                          prizes  \\\n",
       "0     3m1f          Soft  19 fences   [2922.5, 875.0, 420.0, 192.5]   \n",
       "1       2m          Soft  12 fences                              []   \n",
       "2    1m7½f  Good To Firm  12 fences          [2238.0, 618.0, 294.0]   \n",
       "3       2m  Good To Firm        NaN  [5117.0, 1526.0, 728.0, 329.0]   \n",
       "4     2m6f          Good        NaN          [2344.8, 652.8, 314.4]   \n",
       "\n",
       "   winningTime   prize  metric countryCode ncond  class currency  \n",
       "0        398.3  4409.0  5028.0          GB     5      0      NaN  \n",
       "1        267.0     NaN  3218.0          IE     5      0      NaN  \n",
       "2        238.0  3150.0  3116.5          GB     2      0      NaN  \n",
       "3        243.8  7700.0  3218.0          GB     2      0      NaN  \n",
       "4        330.7  3312.0  4424.0          GB     1      0      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nRowsRead = None # specify 'None' if want to read whole file\n",
    "df2 = pd.DataFrame()\n",
    "for file in race_files:\n",
    "    csv_data = pd.read_csv(file, delimiter=',', nrows = nRowsRead)\n",
    "    df2 = df2.append(csv_data, ignore_index=True)\n",
    "df2.dataframeName = 'races'\n",
    "nRow, nCol = df2.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409a4c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going:  ['Soft' 'Good To Firm' 'Good' 'Standard' 'Yielding' 'Good To Soft' 'Heavy'\n",
      " 'Good To Yielding' 'Slow' 'Firm' 'Yielding To Soft' 'Hard' 'Fast'\n",
      " 'Soft To Heavy' 'Very Soft' nan 'Holding' 'Sloppy' 'Muddy'\n",
      " 'Standard To Slow' 'Standard To Fast' 'Frozen' 'Abandoned'] Count:  Good                103936\n",
      "Good To Firm         69409\n",
      "Standard             56992\n",
      "Soft                 45755\n",
      "Good To Soft         38286\n",
      "Heavy                22801\n",
      "Firm                 17610\n",
      "Fast                  9578\n",
      "Yielding              7054\n",
      "Good To Yielding      5507\n",
      "Yielding To Soft      5004\n",
      "Very Soft             4540\n",
      "Standard To Slow      3573\n",
      "Soft To Heavy         3562\n",
      "Slow                   995\n",
      "Sloppy                 638\n",
      "Hard                   495\n",
      "Standard To Fast       373\n",
      "Muddy                  305\n",
      "Holding                 65\n",
      "NaN                     48\n",
      "Frozen                  37\n",
      "Abandoned                9\n",
      "Name: condition, dtype: int64\n",
      "rclass:  [nan 'Class 1' 'Class 6' 'Class 4' 'Class 5' 'Class 2' 'Class 3' 'Class 7'] Count:  NaN        152992\n",
      "Class 4     76194\n",
      "Class 5     60188\n",
      "Class 6     47963\n",
      "Class 3     32770\n",
      "Class 2     12932\n",
      "Class 1     11649\n",
      "Class 7      1884\n",
      "Name: rclass, dtype: int64\n",
      "Band:  [nan '0-125' '0-115' '0-135' '0-70' '0-90' '0-80' '0-145' '0-60' '0-105'\n",
      " '0-140' '0-100' '0-130' '0-110' '0-85' '0-75' '0-95' '0-120' '0-150'\n",
      " '0-65' '0-155' '0-123' '0-109' '0-116' '0-102' '0-112' '0-137' '95-116'\n",
      " '0-144' '88-116' '0-55' '0-50' '75-95' '0-99' '102-123' '0-114' '0-113'\n",
      " '95-109' '0-132' '60-90' '67-95' '88-109' '0-127' '0-133' '0-106' '50-85'\n",
      " '55-90' '50-95' '60-105' '50-90' '0-92' '0-72' '0-126' '0-160' '0-88'\n",
      " '0-82' '60-95' '60-92' '0-77' '50-87' '60-99' '45-70' '67-102' '0-78'\n",
      " '60-93' '65-95' '0-68' '74-102' '60-100' '70-102' '70-109' '74-109' '--'\n",
      " '60-81' '60-88' '67-109' '81-123' '74-116' '50-80' '40-70' '65-97' '0-86'\n",
      " '0-84' '0-81' '0-73' '81-116' '67-88' '88-130' '55-75' '0-74' '0-71'\n",
      " '0-45' '74-95' '40-65' '40-75' '81-109' '50-70' '45-75' '50-75' '70-95'\n",
      " '70-88' '74-88' '81-102' '0-76' '0-69' '0-66' '0-79' '0-96' '0-98' '0-94'\n",
      " '0-83' '0-67' '0-93' '0-40' '0-35' '0-63' '70-116' '90-105' '0-52'\n",
      " '85-100' '95-110' '90-110' '95-112' '33-60' '37-70' '70-100' '46-55'\n",
      " '0-101' '40-60' '37-60' '81-95' '0-104' '0-91' '60-80' '33-70' '81-130'\n",
      " '0-89' '0-87' '0-97' '0-64' '0-62' '0-107' '0-103' '85-105' '100-112'\n",
      " '36-60' '74-123' '45-90' '45-80' '88-140' '0-58' '45-60' '55-85' '0-57'\n",
      " '0-53' '0-54' '95-115' '95-118' '42-60' '47-70' '42-70' '42-65' '47-65'\n",
      " '47-75' '47-80' '47-60' '65-85' '55-70' '42-75' '52-90' '52-80' '60-85'\n",
      " '55-80' '52-85' '88-123' '60-75' '52-70' '52-75' '77-90' '100-118'\n",
      " '100-110' '100-113' '100-111' '100-115' '95-105' '100-129' '100-116'\n",
      " '45-65' '80-95' '95-119' '100-119' '80-102' '0-56' '80-109' '95-120'\n",
      " '80-116' '75-100' '65-90' '80-100' '80-105' '95-122' '70-85' '100-122'\n",
      " '65-80' '50-65' '70-90' '80-98' '90-102' '95-113' '85-98' '75-90'\n",
      " '95-123' '95-130' '85-110' '80-123' '95-108' '85-99' '95-104' '0-175'\n",
      " '76-90' '66-80' '82-100' '72-86' '20-50' '80-93' '85-97' '70-82' '80-94'\n",
      " '95-107' '100-109' '80-91' '51-70' '66-85' '56-70' '61-75' '86-105'\n",
      " '59-73' '68-84' '69-83' '69-89' '55-69' '60-74' '74-94' '84-104' '60-79'\n",
      " '80-99' '84-99' '74-89' '79-99' '58-74' '69-84' '78-94' '64-79' '64-84'\n",
      " '54-69' '95-111' '100-123' '70-87' '95-121' '70-84' '75-89' '63-76'\n",
      " '70-79' '75-88' '63-79' '68-98' '66-84' '71-84' '76-88' '76-92' '84-98'\n",
      " '65-79' '95-114' '78-93' '98-108' '65-75' '66-89' '95-117' '80-92'\n",
      " '86-98' '81-93' '85-95' '77-94' '65-77' '76-84' '76-99' '71-98' '71-92'\n",
      " '84-103' '73-89' '0-59' '76-89' '85-102' '86-94' '72-82' '52-74' '72-84'\n",
      " '70-96' '85-104' '71-82' '100-108' '100-114' '85-94' '65-88' '71-83'\n",
      " '71-95' '78-92' '78-89' '64-96' '70-98' '68-92' '90-108' '60-87' '65-93'\n",
      " '85-112' '65-94' '85-107' '80-130' '59-75' '90-111' '70-91' '95-106'\n",
      " '92-108' '85-93' '90-107' '86-99' '70-80' '96-109' '85-103' '70-93'\n",
      " '60-89' '75-94' '64-90' '78-99' '65-91' '80-108' '65-99' '75-103'\n",
      " '75-101' '75-111' '75-105' '75-84' '65-78' '70-83' '60-84' '65-82'\n",
      " '40-78' '67-78' '90-109' '75-93' '55-65' '76-94' '90-118' '75-85' '75-92'\n",
      " '75-87' '64-80' '77-89' '65-84' '55-81' '0-61' '60-83' '40-77' '65-89'\n",
      " '85-101'] Count:  NaN       231309\n",
      "0-70       18656\n",
      "0-75       12922\n",
      "0-85       11816\n",
      "0-100      10602\n",
      "           ...  \n",
      "60-83          1\n",
      "70-79          1\n",
      "73-89          1\n",
      "80-108         1\n",
      "95-121         1\n",
      "Name: band, Length: 365, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Going: \", df2[\"condition\"].unique(), \"Count: \", df2[\"condition\"].value_counts(dropna=False))\n",
    "print(f\"rclass: \", df2[\"rclass\"].unique(), \"Count: \", df2[\"rclass\"].value_counts(dropna=False))\n",
    "print(f\"Band: \", df2[\"band\"].unique(), \"Count: \", df2[\"band\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f04e2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Good': ' 3', 'Good To Firm': '2', 'Standard': '3', 'Soft': '5', 'Good To Soft': '4', 'Heavy': '8', 'Firm': '1', 'Fast': '1', 'Yielding': '3', 'Good To Yielding': '4', 'Yielding To Soft': '5', 'Very Soft': '7', 'Standard To Slow': '5', 'Soft To Heavy': '6', 'Slow': '6', 'Sloppy': '8', 'Hard': '1', 'Standard To Fast': '2', 'Muddy': '8', 'Holding': '5', 'Frozen': '9', 'Abandoned': '10'}\n"
     ]
    }
   ],
   "source": [
    "#Convert condtion to numeric\n",
    "import csv\n",
    "# Read the CSV file into a list of dictionaries\n",
    "going_map = {}\n",
    "\n",
    "with open('.\\horses\\going.csv', mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader) #skip header\n",
    "    for row in reader:\n",
    "        key, value = row\n",
    "        going_map[key] = value\n",
    "\n",
    "print(going_map)\n",
    "\n",
    "df2['ncond'] = df2['condition'].map(going_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d585c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Class 1': ' 1', 'Class 2': ' 2', 'Class 3': ' 3', 'Class 4': ' 4', 'Class 5': ' 5', 'Class 6': ' 6', 'Class 7': ' 7'}\n"
     ]
    }
   ],
   "source": [
    "#convert races.class to numeric\n",
    "# Read the CSV file into a list of dictionaries\n",
    "class_map = {}\n",
    "\n",
    "with open('.\\horses\\class.csv', mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader) #skip header\n",
    "    for row in reader:\n",
    "        key, value = row\n",
    "        class_map[key] = value\n",
    "\n",
    "print(class_map)\n",
    "\n",
    "df2['rclass'] = df2['rclass'].map(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "965fac8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop columns\n",
    "df2 = df2.drop(['time', 'title', 'band', 'ages', 'distance', 'condition', 'hurdles', 'prizes', \n",
    "         'winningTime', 'prize', 'countryCode', 'class', 'currency'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9542b26b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82146300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>horseName</th>\n",
       "      <th>age</th>\n",
       "      <th>saddle</th>\n",
       "      <th>decimalPrice</th>\n",
       "      <th>isFav</th>\n",
       "      <th>trainerName</th>\n",
       "      <th>jockeyName</th>\n",
       "      <th>position</th>\n",
       "      <th>RPR</th>\n",
       "      <th>TR</th>\n",
       "      <th>OR</th>\n",
       "      <th>weight</th>\n",
       "      <th>res_win</th>\n",
       "      <th>res_place</th>\n",
       "      <th>course</th>\n",
       "      <th>date</th>\n",
       "      <th>rclass</th>\n",
       "      <th>metric</th>\n",
       "      <th>ncond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271018</td>\n",
       "      <td>Combermere</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>R G Frost</td>\n",
       "      <td>J Frost</td>\n",
       "      <td>1</td>\n",
       "      <td>111.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Exeter</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5028.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271018</td>\n",
       "      <td>Royal Battery</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>D H Barons</td>\n",
       "      <td>S Earle</td>\n",
       "      <td>2</td>\n",
       "      <td>101.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Exeter</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5028.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>271018</td>\n",
       "      <td>Just So</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0</td>\n",
       "      <td>J D Roberts</td>\n",
       "      <td>S Burrough</td>\n",
       "      <td>3</td>\n",
       "      <td>86.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Exeter</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5028.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271018</td>\n",
       "      <td>Mandraki Shuffle</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>Oliver Sherwood</td>\n",
       "      <td>M Richards</td>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Exeter</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5028.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271018</td>\n",
       "      <td>Turnberry Dawn</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0</td>\n",
       "      <td>T B Hallett</td>\n",
       "      <td>P Richards</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Exeter</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5028.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>326330</td>\n",
       "      <td>Birmingham's Pride</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg Hollinshead</td>\n",
       "      <td>C Hodgson</td>\n",
       "      <td>3</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Southwell (AW)</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>326330</td>\n",
       "      <td>Razeen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0</td>\n",
       "      <td>J G Fitzgerald</td>\n",
       "      <td>Kieren Fallon</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Southwell (AW)</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>326330</td>\n",
       "      <td>Trace Of Irony</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>Chris Wall</td>\n",
       "      <td>Billy Newnes</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Southwell (AW)</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>326330</td>\n",
       "      <td>Gargoor</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0</td>\n",
       "      <td>N A Callaghan</td>\n",
       "      <td>Michael Tebbutt</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Southwell (AW)</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>326330</td>\n",
       "      <td>Fishki</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1</td>\n",
       "      <td>B Hanbury</td>\n",
       "      <td>B Raymond</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Southwell (AW)</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rid           horseName  age  saddle  decimalPrice  isFav  \\\n",
       "0   271018          Combermere  6.0     0.0      0.222222      0   \n",
       "1   271018       Royal Battery  6.0     0.0      0.090909      0   \n",
       "2   271018             Just So  7.0     0.0      0.029412      0   \n",
       "3   271018    Mandraki Shuffle  8.0     0.0      0.090909      0   \n",
       "4   271018      Turnberry Dawn  8.0     0.0      0.047619      0   \n",
       "..     ...                 ...  ...     ...           ...    ...   \n",
       "95  326330  Birmingham's Pride  4.0     0.0      0.038462      0   \n",
       "96  326330              Razeen  5.0     0.0      0.133333      0   \n",
       "97  326330      Trace Of Irony  4.0     0.0      0.083333      0   \n",
       "98  326330             Gargoor  4.0     0.0      0.058824      0   \n",
       "99  326330              Fishki  4.0     0.0      0.363636      1   \n",
       "\n",
       "        trainerName       jockeyName  position    RPR    TR  OR  weight  \\\n",
       "0         R G Frost          J Frost         1  111.0  94.0 NaN      69   \n",
       "1        D H Barons          S Earle         2  101.0  88.0 NaN      69   \n",
       "2       J D Roberts       S Burrough         3   86.0  71.0 NaN      66   \n",
       "3   Oliver Sherwood       M Richards         4   66.0  65.0 NaN      69   \n",
       "4       T B Hallett       P Richards         5    NaN  45.0 NaN      69   \n",
       "..              ...              ...       ...    ...   ...  ..     ...   \n",
       "95  Reg Hollinshead        C Hodgson         3   44.0   NaN NaN      52   \n",
       "96   J G Fitzgerald    Kieren Fallon         4    NaN   NaN NaN      58   \n",
       "97       Chris Wall     Billy Newnes         5    NaN   NaN NaN      55   \n",
       "98    N A Callaghan  Michael Tebbutt         6    NaN   NaN NaN      54   \n",
       "99        B Hanbury        B Raymond         7    NaN   NaN NaN      55   \n",
       "\n",
       "    res_win  res_place          course      date rclass  metric ncond  \n",
       "0       1.0        1.0          Exeter  90/01/01    NaN  5028.0     5  \n",
       "1       0.0        1.0          Exeter  90/01/01    NaN  5028.0     5  \n",
       "2       0.0        1.0          Exeter  90/01/01    NaN  5028.0     5  \n",
       "3       0.0        0.0          Exeter  90/01/01    NaN  5028.0     5  \n",
       "4       0.0        0.0          Exeter  90/01/01    NaN  5028.0     5  \n",
       "..      ...        ...             ...       ...    ...     ...   ...  \n",
       "95      0.0        1.0  Southwell (AW)  90/01/01    NaN  1609.0     3  \n",
       "96      0.0        0.0  Southwell (AW)  90/01/01    NaN  1609.0     3  \n",
       "97      0.0        0.0  Southwell (AW)  90/01/01    NaN  1609.0     3  \n",
       "98      0.0        0.0  Southwell (AW)  90/01/01    NaN  1609.0     3  \n",
       "99      0.0        0.0  Southwell (AW)  90/01/01    NaN  1609.0     3  \n",
       "\n",
       "[100 rows x 20 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge dataframes on rid\n",
    "df = df1.merge(df2, on='rid', how='inner')\n",
    "print(df.size)\n",
    "df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a936251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4107315, 20)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "950ead09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      rid  horseName  age  saddle  decimalPrice  isFav  trainerName  \\\n",
      "0  271018          0  6.0     0.0      0.222222      0            0   \n",
      "1  271018          1  6.0     0.0      0.090909      0            1   \n",
      "2  271018          2  7.0     0.0      0.029412      0            2   \n",
      "3  271018          3  8.0     0.0      0.090909      0            3   \n",
      "4  271018          4  8.0     0.0      0.047619      0            4   \n",
      "\n",
      "   jockeyName  position    RPR    TR  OR  weight  res_win  res_place  course  \\\n",
      "0           0         1  111.0  94.0 NaN      69      1.0        1.0       0   \n",
      "1           1         2  101.0  88.0 NaN      69      0.0        1.0       0   \n",
      "2           2         3   86.0  71.0 NaN      66      0.0        1.0       0   \n",
      "3           3         4   66.0  65.0 NaN      69      0.0        0.0       0   \n",
      "4           4         5    NaN  45.0 NaN      69      0.0        0.0       0   \n",
      "\n",
      "       date rclass  metric ncond  \n",
      "0  90/01/01    NaN  5028.0     5  \n",
      "1  90/01/01    NaN  5028.0     5  \n",
      "2  90/01/01    NaN  5028.0     5  \n",
      "3  90/01/01    NaN  5028.0     5  \n",
      "4  90/01/01    NaN  5028.0     5  \n",
      "            ID     Original_Text\n",
      "0            0        Combermere\n",
      "1            1     Royal Battery\n",
      "2            2           Just So\n",
      "3            3  Mandraki Shuffle\n",
      "4            4    Turnberry Dawn\n",
      "...        ...               ...\n",
      "371864  371864          Dynamore\n",
      "371865  371865    Flying Sardine\n",
      "371866  371866     Aimee's Jewel\n",
      "371867  371867     Times Ticking\n",
      "371868  371868        Awesome Al\n",
      "\n",
      "[371869 rows x 2 columns]\n",
      "          ID                       Original_Text\n",
      "0          0                           R G Frost\n",
      "1          1                          D H Barons\n",
      "2          2                         J D Roberts\n",
      "3          3                     Oliver Sherwood\n",
      "4          4                         T B Hallett\n",
      "...      ...                                 ...\n",
      "18443  18443                         Sarah Bowen\n",
      "18444  18444                       A Al Mehairbi\n",
      "18445  18445  Steven O'Dea &amp; Matthew Hoysted\n",
      "18446  18446                    Hitoshi Kotegawa\n",
      "18447  18447                        Buddy Lammas\n",
      "\n",
      "[18448 rows x 2 columns]\n",
      "          ID   Original_Text\n",
      "0          0         J Frost\n",
      "1          1         S Earle\n",
      "2          2      S Burrough\n",
      "3          3      M Richards\n",
      "4          4      P Richards\n",
      "...      ...             ...\n",
      "17716  17716   Miss R Murphy\n",
      "17717  17717    Lauren Maher\n",
      "17718  17718  Mr Kane Yeoman\n",
      "17719  17719    Sam O'Malley\n",
      "17720  17720   Hazel Schofer\n",
      "\n",
      "[17721 rows x 2 columns]\n",
      "      ID      Original_Text\n",
      "0      0             Exeter\n",
      "1      1      Tramore (IRE)\n",
      "2      2          Catterick\n",
      "3      3         Cheltenham\n",
      "4      4            Windsor\n",
      "..   ...                ...\n",
      "435  435  Fonner Park (USA)\n",
      "436  436    Balaklava (AUS)\n",
      "437  437        Vittel (FR)\n",
      "438  438        Evreux (FR)\n",
      "439  439       Ankara (TUR)\n",
      "\n",
      "[440 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Factorise text columns\n",
    "df['horseName'], unique_text = pd.factorize(df['horseName'])\n",
    "\n",
    "# Create a DataFrame for the mapping\n",
    "horsename_df = pd.DataFrame({\n",
    "    'ID': range(len(unique_text)),\n",
    "    'Original_Text': unique_text\n",
    "})\n",
    "\n",
    "df['trainerName'], unique_text = pd.factorize(df['trainerName'])\n",
    "\n",
    "# Create a DataFrame for the mapping\n",
    "trainername_df = pd.DataFrame({\n",
    "    'ID': range(len(unique_text)),\n",
    "    'Original_Text': unique_text\n",
    "})\n",
    "\n",
    "df['jockeyName'], unique_text = pd.factorize(df['jockeyName'])\n",
    "\n",
    "# Create a DataFrame for the mapping\n",
    "jockeyname_df = pd.DataFrame({\n",
    "    'ID': range(len(unique_text)),\n",
    "    'Original_Text': unique_text\n",
    "})\n",
    "\n",
    "df['course'], unique_text = pd.factorize(df['course'])\n",
    "\n",
    "# Create a DataFrame for the mapping\n",
    "course_df = pd.DataFrame({\n",
    "    'ID': range(len(unique_text)),\n",
    "    'Original_Text': unique_text\n",
    "})\n",
    "print(df.head())\n",
    "print(horsename_df)\n",
    "print(trainername_df)\n",
    "print(jockeyname_df)\n",
    "print(course_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9528359b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94700efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>horseName</th>\n",
       "      <th>age</th>\n",
       "      <th>saddle</th>\n",
       "      <th>decimalPrice</th>\n",
       "      <th>isFav</th>\n",
       "      <th>trainerName</th>\n",
       "      <th>jockeyName</th>\n",
       "      <th>position</th>\n",
       "      <th>RPR</th>\n",
       "      <th>TR</th>\n",
       "      <th>OR</th>\n",
       "      <th>weight</th>\n",
       "      <th>res_win</th>\n",
       "      <th>res_place</th>\n",
       "      <th>course</th>\n",
       "      <th>date</th>\n",
       "      <th>rclass</th>\n",
       "      <th>metric</th>\n",
       "      <th>ncond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271018</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5028.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271018</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>101.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5028.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>271018</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>86.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5028.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271018</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5028.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271018</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90/01/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5028.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rid  horseName  age  saddle  decimalPrice  isFav  trainerName  \\\n",
       "0  271018          0  6.0     0.0      0.222222      0            0   \n",
       "1  271018          1  6.0     0.0      0.090909      0            1   \n",
       "2  271018          2  7.0     0.0      0.029412      0            2   \n",
       "3  271018          3  8.0     0.0      0.090909      0            3   \n",
       "4  271018          4  8.0     0.0      0.047619      0            4   \n",
       "\n",
       "   jockeyName  position    RPR    TR  OR  weight  res_win  res_place  course  \\\n",
       "0           0         1  111.0  94.0 NaN      69      1.0        1.0       0   \n",
       "1           1         2  101.0  88.0 NaN      69      0.0        1.0       0   \n",
       "2           2         3   86.0  71.0 NaN      66      0.0        1.0       0   \n",
       "3           3         4   66.0  65.0 NaN      69      0.0        0.0       0   \n",
       "4           4         5    NaN  45.0 NaN      69      0.0        0.0       0   \n",
       "\n",
       "       date rclass  metric ncond  \n",
       "0  90/01/01    NaN  5028.0     5  \n",
       "1  90/01/01    NaN  5028.0     5  \n",
       "2  90/01/01    NaN  5028.0     5  \n",
       "3  90/01/01    NaN  5028.0     5  \n",
       "4  90/01/01    NaN  5028.0     5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Export dataset\n",
    "df.head()\n",
    "#df.to_csv('testfile.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31b7fcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [horseName, age, saddle, decimalPrice, isFav, trainerName, jockeyName, RPR, TR, weight, res_win, course, metric, ncond]\n",
      "Index: []\n",
      "(2291748, 14)\n"
     ]
    }
   ],
   "source": [
    "#final data clearup\n",
    "df = df.drop(['rid', 'position', 'res_place', 'OR', 'rclass', 'date'], axis=1)\n",
    "df = df.dropna()\n",
    "#Drop rows with a Nan\n",
    "rows_with_nan = df[df.isna().any(axis=1)]\n",
    "#check no Nan rows\n",
    "print(rows_with_nan)\n",
    "#Convert decimal to integer\n",
    "df['age'] = df['age'].astype(int)\n",
    "df['saddle'] = df['saddle'].astype(int)\n",
    "df['res_win'] = df['res_win'].astype(int)\n",
    "df['ncond'] = df['ncond'].astype(int)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0679efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['res_win'], axis=1)\n",
    "y = df['res_win']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a87ef39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions pproduced by MS Azure AutoML\n",
    "def generate_algorithm_config_0():\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    \n",
    "    algorithm = XGBClassifier(\n",
    "        base_score=0.5,\n",
    "        booster='gbtree',\n",
    "        colsample_bylevel=1,\n",
    "        colsample_bynode=1,\n",
    "        colsample_bytree=0.7,\n",
    "        eta=0.4,\n",
    "        gamma=0,\n",
    "        gpu_id=-1,\n",
    "        importance_type='gain',\n",
    "        interaction_constraints='',\n",
    "        learning_rate=0.400000006,\n",
    "        max_delta_step=0,\n",
    "        max_depth=4,\n",
    "        max_leaves=0,\n",
    "        min_child_weight=1,\n",
    "        missing=numpy.nan,\n",
    "        monotone_constraints='()',\n",
    "        n_estimators=800,\n",
    "        n_jobs=0,\n",
    "        num_parallel_tree=1,\n",
    "        objective='reg:logistic',\n",
    "        random_state=0,\n",
    "        reg_alpha=1.875,\n",
    "        reg_lambda=0.7291666666666667,\n",
    "        scale_pos_weight=1,\n",
    "        subsample=0.8,\n",
    "        tree_method='auto',\n",
    "        validate_parameters=1,\n",
    "        verbose=-10,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    return algorithm\n",
    "\n",
    "def generate_algorithm_config_1():\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    \n",
    "    algorithm = XGBClassifier(\n",
    "        base_score=0.5,\n",
    "        booster='gbtree',\n",
    "        colsample_bylevel=1,\n",
    "        colsample_bynode=1,\n",
    "        colsample_bytree=0.6,\n",
    "        eta=0.3,\n",
    "        gamma=0,\n",
    "        gpu_id=-1,\n",
    "        importance_type='gain',\n",
    "        interaction_constraints='',\n",
    "        learning_rate=0.300000012,\n",
    "        max_delta_step=0,\n",
    "        max_depth=8,\n",
    "        max_leaves=63,\n",
    "        min_child_weight=1,\n",
    "        missing=numpy.nan,\n",
    "        monotone_constraints='()',\n",
    "        n_estimators=200,\n",
    "        n_jobs=0,\n",
    "        num_parallel_tree=1,\n",
    "        objective='reg:logistic',\n",
    "        random_state=0,\n",
    "        reg_alpha=0.8333333333333334,\n",
    "        reg_lambda=1.4583333333333335,\n",
    "        scale_pos_weight=1,\n",
    "        subsample=0.7,\n",
    "        tree_method='auto',\n",
    "        validate_parameters=1,\n",
    "        verbose=-10,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    return algorithm\n",
    "\n",
    "def generate_algorithm_config_2():\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    \n",
    "    algorithm = XGBClassifier(\n",
    "        base_score=0.5,\n",
    "        booster='gbtree',\n",
    "        colsample_bylevel=1,\n",
    "        colsample_bynode=1,\n",
    "        colsample_bytree=0.5,\n",
    "        eta=0.3,\n",
    "        gamma=0.1,\n",
    "        gpu_id=-1,\n",
    "        importance_type='gain',\n",
    "        interaction_constraints='',\n",
    "        learning_rate=0.300000012,\n",
    "        max_delta_step=0,\n",
    "        max_depth=6,\n",
    "        max_leaves=31,\n",
    "        min_child_weight=1,\n",
    "        missing=numpy.nan,\n",
    "        monotone_constraints='()',\n",
    "        n_estimators=600,\n",
    "        n_jobs=0,\n",
    "        num_parallel_tree=1,\n",
    "        objective='reg:logistic',\n",
    "        random_state=0,\n",
    "        reg_alpha=1.3541666666666667,\n",
    "        reg_lambda=0.10416666666666667,\n",
    "        scale_pos_weight=1,\n",
    "        subsample=0.5,\n",
    "        tree_method='auto',\n",
    "        validate_parameters=1,\n",
    "        verbose=-10,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    return algorithm\n",
    "\n",
    "def generate_algorithm_config_3():\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    \n",
    "    algorithm = XGBClassifier(\n",
    "        base_score=0.5,\n",
    "        booster='gbtree',\n",
    "        colsample_bylevel=1,\n",
    "        colsample_bynode=1,\n",
    "        colsample_bytree=0.5,\n",
    "        eta=0.3,\n",
    "        gamma=0,\n",
    "        gpu_id=-1,\n",
    "        importance_type='gain',\n",
    "        interaction_constraints='',\n",
    "        learning_rate=0.300000012,\n",
    "        max_delta_step=0,\n",
    "        max_depth=9,\n",
    "        max_leaves=7,\n",
    "        min_child_weight=1,\n",
    "        missing=numpy.nan,\n",
    "        monotone_constraints='()',\n",
    "        n_estimators=200,\n",
    "        n_jobs=0,\n",
    "        num_parallel_tree=1,\n",
    "        objective='reg:logistic',\n",
    "        random_state=0,\n",
    "        reg_alpha=0.9375,\n",
    "        reg_lambda=1.5625,\n",
    "        scale_pos_weight=1,\n",
    "        subsample=0.7,\n",
    "        tree_method='auto',\n",
    "        validate_parameters=1,\n",
    "        verbose=-10,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    return algorithm\n",
    "\n",
    "def generate_algorithm_config_4():\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    \n",
    "    algorithm = XGBClassifier(\n",
    "        base_score=0.5,\n",
    "        booster='gbtree',\n",
    "        colsample_bylevel=1,\n",
    "        colsample_bynode=1,\n",
    "        colsample_bytree=1,\n",
    "        eta=0.3,\n",
    "        gamma=10,\n",
    "        gpu_id=-1,\n",
    "        importance_type='gain',\n",
    "        interaction_constraints='',\n",
    "        learning_rate=0.300000012,\n",
    "        max_delta_step=0,\n",
    "        max_depth=9,\n",
    "        max_leaves=63,\n",
    "        min_child_weight=1,\n",
    "        missing=numpy.nan,\n",
    "        monotone_constraints='()',\n",
    "        n_estimators=100,\n",
    "        n_jobs=0,\n",
    "        num_parallel_tree=1,\n",
    "        objective='reg:logistic',\n",
    "        random_state=0,\n",
    "        reg_alpha=1.9791666666666667,\n",
    "        reg_lambda=1.3541666666666667,\n",
    "        scale_pos_weight=1,\n",
    "        subsample=0.7,\n",
    "        tree_method='auto',\n",
    "        validate_parameters=1,\n",
    "        verbose=-10,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    return algorithm\n",
    "\n",
    "def generate_algorithm_config_5():\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    \n",
    "    algorithm = XGBClassifier(\n",
    "        base_score=0.5,\n",
    "        booster='gbtree',\n",
    "        colsample_bylevel=0.5,\n",
    "        colsample_bynode=1,\n",
    "        colsample_bytree=1,\n",
    "        eta=0.3,\n",
    "        gamma=0,\n",
    "        gpu_id=-1,\n",
    "        importance_type='gain',\n",
    "        interaction_constraints='',\n",
    "        learning_rate=0.300000012,\n",
    "        max_delta_step=0,\n",
    "        max_depth=10,\n",
    "        max_leaves=0,\n",
    "        min_child_weight=1,\n",
    "        missing=numpy.nan,\n",
    "        monotone_constraints='()',\n",
    "        n_estimators=200,\n",
    "        n_jobs=0,\n",
    "        num_parallel_tree=1,\n",
    "        objective='reg:logistic',\n",
    "        random_state=0,\n",
    "        reg_alpha=0.9375,\n",
    "        reg_lambda=1.25,\n",
    "        scale_pos_weight=1,\n",
    "        subsample=1,\n",
    "        tree_method='auto',\n",
    "        validate_parameters=1,\n",
    "        verbose=-10,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    return algorithm\n",
    "\n",
    "def generate_algorithm_config_6():\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    \n",
    "    algorithm = XGBClassifier(\n",
    "        base_score=0.5,\n",
    "        booster='gbtree',\n",
    "        colsample_bylevel=1,\n",
    "        colsample_bynode=1,\n",
    "        colsample_bytree=1,\n",
    "        eta=0.4,\n",
    "        gamma=0,\n",
    "        gpu_id=-1,\n",
    "        importance_type='gain',\n",
    "        interaction_constraints='',\n",
    "        learning_rate=0.400000006,\n",
    "        max_delta_step=0,\n",
    "        max_depth=9,\n",
    "        max_leaves=15,\n",
    "        min_child_weight=1,\n",
    "        missing=numpy.nan,\n",
    "        monotone_constraints='()',\n",
    "        n_estimators=100,\n",
    "        n_jobs=0,\n",
    "        num_parallel_tree=1,\n",
    "        objective='reg:logistic',\n",
    "        random_state=0,\n",
    "        reg_alpha=2.5,\n",
    "        reg_lambda=2.5,\n",
    "        scale_pos_weight=1,\n",
    "        subsample=0.9,\n",
    "        tree_method='auto',\n",
    "        validate_parameters=1,\n",
    "        verbose=-10,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    return algorithm\n",
    "\n",
    "def generate_algorithm_config_7():\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    \n",
    "    algorithm = XGBClassifier(\n",
    "        base_score=0.5,\n",
    "        booster='gbtree',\n",
    "        colsample_bylevel=1,\n",
    "        colsample_bynode=1,\n",
    "        colsample_bytree=0.8,\n",
    "        eta=0.3,\n",
    "        gamma=0,\n",
    "        gpu_id=-1,\n",
    "        importance_type='gain',\n",
    "        interaction_constraints='',\n",
    "        learning_rate=0.300000012,\n",
    "        max_delta_step=0,\n",
    "        max_depth=10,\n",
    "        max_leaves=0,\n",
    "        min_child_weight=1,\n",
    "        missing=numpy.nan,\n",
    "        monotone_constraints='()',\n",
    "        n_estimators=100,\n",
    "        n_jobs=0,\n",
    "        num_parallel_tree=1,\n",
    "        objective='reg:logistic',\n",
    "        random_state=0,\n",
    "        reg_alpha=0,\n",
    "        reg_lambda=0.3125,\n",
    "        scale_pos_weight=1,\n",
    "        subsample=0.8,\n",
    "        tree_method='auto',\n",
    "        validate_parameters=1,\n",
    "        verbose=-10,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    return algorithm\n",
    "    \n",
    "def generate_algorithm_config_8():\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    \n",
    "    algorithm = XGBClassifier(\n",
    "        base_score=0.5,\n",
    "        booster='gbtree',\n",
    "        colsample_bylevel=1,\n",
    "        colsample_bynode=1,\n",
    "        colsample_bytree=1,\n",
    "        eta=0.5,\n",
    "        gamma=0.1,\n",
    "        gpu_id=-1,\n",
    "        importance_type='gain',\n",
    "        interaction_constraints='',\n",
    "        learning_rate=0.5,\n",
    "        max_delta_step=0,\n",
    "        max_depth=10,\n",
    "        max_leaves=255,\n",
    "        min_child_weight=1,\n",
    "        missing=numpy.nan,\n",
    "        monotone_constraints='()',\n",
    "        n_estimators=600,\n",
    "        n_jobs=0,\n",
    "        num_parallel_tree=1,\n",
    "        objective='reg:logistic',\n",
    "        random_state=0,\n",
    "        reg_alpha=0,\n",
    "        reg_lambda=1.4583333333333335,\n",
    "        scale_pos_weight=1,\n",
    "        subsample=0.8,\n",
    "        tree_method='auto',\n",
    "        validate_parameters=1,\n",
    "        verbose=-10,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    return algorithm\n",
    "    \n",
    "def generate_algorithm_config_9():\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    \n",
    "    algorithm = XGBClassifier(\n",
    "        base_score=0.5,\n",
    "        booster='gbtree',\n",
    "        colsample_bylevel=1,\n",
    "        colsample_bynode=1,\n",
    "        colsample_bytree=0.8,\n",
    "        eta=0.5,\n",
    "        gamma=0,\n",
    "        gpu_id=-1,\n",
    "        importance_type='gain',\n",
    "        interaction_constraints='',\n",
    "        learning_rate=0.5,\n",
    "        max_delta_step=0,\n",
    "        max_depth=8,\n",
    "        max_leaves=255,\n",
    "        min_child_weight=1,\n",
    "        missing=numpy.nan,\n",
    "        monotone_constraints='()',\n",
    "        n_estimators=400,\n",
    "        n_jobs=0,\n",
    "        num_parallel_tree=1,\n",
    "        objective='reg:logistic',\n",
    "        random_state=0,\n",
    "        reg_alpha=0,\n",
    "        reg_lambda=1.7708333333333335,\n",
    "        scale_pos_weight=1,\n",
    "        subsample=0.7,\n",
    "        tree_method='auto',\n",
    "        validate_parameters=1,\n",
    "        verbose=-10,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    return algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efc9c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pipeline():\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    num_classifiers = 10\n",
    "    xgb_classifiers = [(\"xgb0\", generate_algorithm_config_0()),\n",
    "                       (\"xgb1\", generate_algorithm_config_1()),\n",
    "                       (\"xgb2\", generate_algorithm_config_2()),\n",
    "                       (\"xgb3\", generate_algorithm_config_3()),\n",
    "                       (\"xgb4\", generate_algorithm_config_4()),\n",
    "                       (\"xgb5\", generate_algorithm_config_5()),\n",
    "                       (\"xgb6\", generate_algorithm_config_6()),\n",
    "                       (\"xgb7\", generate_algorithm_config_7()),\n",
    "                       (\"xgb8\", generate_algorithm_config_8()),\n",
    "                       (\"xgb9\", generate_algorithm_config_9()),\n",
    "                      ]\n",
    "    print(xgb_classifiers)\n",
    "    #List containing model weights produced by MS Azure AutoML\n",
    "    weights=[0.26666666666666666, 0.06666666666666667, 0.13333333333333333, 0.06666666666666667, 0.06666666666666667, 0.13333333333333333, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
    "    voting_clf = VotingClassifier(estimators=xgb_classifiers, voting='soft', weights=weights)\n",
    "    pipeline = Pipeline([    ('voting_classifier', voting_clf)])\n",
    "    return pipeline\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3966036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('xgb0', XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,\n",
      "              early_stopping_rounds=None, enable_categorical=False, eta=0.4,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy=None, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.400000006,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=800,\n",
      "              n_jobs=0, num_parallel_tree=1, objective='reg:logistic', ...)), ('xgb1', XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.6,\n",
      "              early_stopping_rounds=None, enable_categorical=False, eta=0.3,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy=None, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=0, max_depth=8, max_leaves=63, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=200,\n",
      "              n_jobs=0, num_parallel_tree=1, objective='reg:logistic', ...)), ('xgb2', XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.5,\n",
      "              early_stopping_rounds=None, enable_categorical=False, eta=0.3,\n",
      "              eval_metric=None, feature_types=None, gamma=0.1, gpu_id=-1,\n",
      "              grow_policy=None, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=31, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=600,\n",
      "              n_jobs=0, num_parallel_tree=1, objective='reg:logistic', ...)), ('xgb3', XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.5,\n",
      "              early_stopping_rounds=None, enable_categorical=False, eta=0.3,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy=None, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=0, max_depth=9, max_leaves=7, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=200,\n",
      "              n_jobs=0, num_parallel_tree=1, objective='reg:logistic', ...)), ('xgb4', XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False, eta=0.3,\n",
      "              eval_metric=None, feature_types=None, gamma=10, gpu_id=-1,\n",
      "              grow_policy=None, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=0, max_depth=9, max_leaves=63, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, objective='reg:logistic', ...)), ('xgb5', XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=0.5, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False, eta=0.3,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy=None, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=200,\n",
      "              n_jobs=0, num_parallel_tree=1, objective='reg:logistic', ...)), ('xgb6', XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False, eta=0.4,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy=None, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.400000006,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=0, max_depth=9, max_leaves=15, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, objective='reg:logistic', ...)), ('xgb7', XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
      "              early_stopping_rounds=None, enable_categorical=False, eta=0.3,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy=None, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, objective='reg:logistic', ...)), ('xgb8', XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False, eta=0.5,\n",
      "              eval_metric=None, feature_types=None, gamma=0.1, gpu_id=-1,\n",
      "              grow_policy=None, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.5, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=0,\n",
      "              max_depth=10, max_leaves=255, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=600, n_jobs=0,\n",
      "              num_parallel_tree=1, objective='reg:logistic', ...)), ('xgb9', XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
      "              early_stopping_rounds=None, enable_categorical=False, eta=0.5,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy=None, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.5, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=0,\n",
      "              max_depth=8, max_leaves=255, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=400, n_jobs=0,\n",
      "              num_parallel_tree=1, objective='reg:logistic', ...))]\n",
      "Pipeline(steps=[('voting_classifier',\n",
      "                 VotingClassifier(estimators=[('xgb0',\n",
      "                                               XGBClassifier(base_score=0.5,\n",
      "                                                             booster='gbtree',\n",
      "                                                             callbacks=None,\n",
      "                                                             colsample_bylevel=1,\n",
      "                                                             colsample_bynode=1,\n",
      "                                                             colsample_bytree=0.7,\n",
      "                                                             early_stopping_rounds=None,\n",
      "                                                             enable_categorical=False,\n",
      "                                                             eta=0.4,\n",
      "                                                             eval_metric=None,\n",
      "                                                             feature_types=None,\n",
      "                                                             gamma=0, gpu_id=-1,\n",
      "                                                             grow_policy=None,\n",
      "                                                             importance_type='gain',\n",
      "                                                             i...\n",
      "                                                             min_child_weight=1,\n",
      "                                                             missing=nan,\n",
      "                                                             monotone_constraints='()',\n",
      "                                                             n_estimators=400,\n",
      "                                                             n_jobs=0,\n",
      "                                                             num_parallel_tree=1,\n",
      "                                                             objective='reg:logistic', ...))],\n",
      "                                  voting='soft',\n",
      "                                  weights=[0.26666666666666666,\n",
      "                                           0.06666666666666667,\n",
      "                                           0.13333333333333333,\n",
      "                                           0.06666666666666667,\n",
      "                                           0.06666666666666667,\n",
      "                                           0.13333333333333333,\n",
      "                                           0.06666666666666667,\n",
      "                                           0.06666666666666667,\n",
      "                                           0.06666666666666667,\n",
      "                                           0.06666666666666667]))])\n"
     ]
    }
   ],
   "source": [
    "#Generate model pipeline and train\n",
    "\n",
    "from azureml.automl.core.inference import inference\n",
    "from azureml.core.run import Run\n",
    "import numpy    \n",
    "import mlflow\n",
    "\n",
    "pipeline = generate_pipeline()\n",
    "print(pipeline)\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "print(\"Model trained\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00069e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.50%\n",
      "F1 score: 33.90%\n",
      "ROC AUC: 87.06%\n",
      "Confusion matrix:  [[392149   8002]\n",
      " [ 44689  13510]]\n",
      "Precision: 62.80%\n",
      "Recall: 23.21%\n",
      "F1 Score Manual Calc: 33.90%\n"
     ]
    }
   ],
   "source": [
    "#Report model metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "print(f\"F1 score: {f1score * 100:.2f}%\")\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "rocscore = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC AUC: {rocscore * 100:.2f}%\")\n",
    "confusionmatrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix: \", confusionmatrix)\n",
    "precision = confusionmatrix[1,1]/(confusionmatrix[1,1]+confusionmatrix[0,1])\n",
    "recall = confusionmatrix[1,1]/(confusionmatrix[1,1]+confusionmatrix[1,0])\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "F1calc = (2 * (precision*recall))/(precision+recall)\n",
    "print(f\"F1 Score Manual Calc: {F1calc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a4d998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff2c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f790e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f1e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43dc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
